---
title: "Practical Machine Learning Project"
output: html_document
---

The goal of this project is to predict the manner in which the participants did the exercise. This is represented by
the "classe" variable in the training set.
 
### Get and clean the data

Read the csv file for training
```{r,eval=FALSE}
pml_training <- read.csv("pml-training.csv")
pml_testing <- read.csv("pml-testing.csv")
```

Remove all columns that contain blanks or NA's
```{r,eval=FALSE}
pml_training[pml_training == ""] <- NA
pml_testing[pml_testing == ""] <- NA
pml_training_clean <- Filter(function(x)!any(is.na(x)), pml_training)
pml_testing_clean <- Filter(function(x)!any(is.na(x)), pml_testing)
```

Remove the first 7 columns since they contain names, timestamps & strings
```{r,eval=FALSE}
pml_training_clean <- pml_training_clean [7:length (pml_training_clean)]
pml_testing_clean <- pml_testing_clean [7:length (pml_testing_clean)]
```

Split the training data into a training set and a cross validation set
```{r,eval=FALSE}
inTrain <- createDataPartition(y = pml_training_clean$classe, p = 0.7, list = FALSE)
training <- pml_training_clean [inTrain, ]
crossvalidation <- pml_training_clean [-inTrain, ]
```

### Model building

Fit a model using random forest to predict the "classe" variable using everything else as a predictor

```{r,eval=FALSE}
model <- randomForest(classe ~ ., data = training)
```

### Error estimation with cross validation

Using the model that we've trained, we're performing a cross validation with the rest of data from the dataset reserved for this reason. 
```{r,eval=FALSE}
predictCrossVal <- predict(model, crossval)
confusionMatrix (crossval$classe, predictCrossVal)
```

The output of the confusionMatrix consists of a cross-tabulation of observed and predicted classes with associated statistics:
```{r,eval=FALSE}
Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1674    0    0    0    0
         B    1 1138    0    0    0
         C    0    3 1023    0    0
         D    0    0    3  961    0
         E    0    0    0    3 1079

Overall Statistics
                                          
               Accuracy : 0.9983          
                 95% CI : (0.9969, 0.9992)
    No Information Rate : 0.2846          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.9979          
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9994   0.9974   0.9971   0.9969   1.0000
Specificity            1.0000   0.9998   0.9994   0.9994   0.9994
Pos Pred Value         1.0000   0.9991   0.9971   0.9969   0.9972
Neg Pred Value         0.9998   0.9994   0.9994   0.9994   1.0000
Prevalence             0.2846   0.1939   0.1743   0.1638   0.1833
Detection Rate         0.2845   0.1934   0.1738   0.1633   0.1833
Detection Prevalence   0.2845   0.1935   0.1743   0.1638   0.1839
Balanced Accuracy      0.9997   0.9986   0.9982   0.9981   0.9997
```
Our model accuracy is 99.83%

### Predict the 20 test cases

Using the testing data set, we predict the "classe" variable
```{r,eval=FALSE}
answers <- predict (model, pml_testing_clean)
```

We then apply our answer array to the function provided by the instructor:
```{r,eval=FALSE}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
pml_write_files(answers)
```

We provide the results here (all successfully submited).
```{r,eval=FALSE}
 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 
 B  A  B  A  A  E  D  B  A  A  B  C  B  A  E  E  A  B  B  B 
Levels: A B C D E
```