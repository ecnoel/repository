---
title: "Practical Machine Learning Project"
output: html_document
---

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data
about personal activity relatively inexpensively. One thing that people regularly do is quantify how much of a
particular activity they do, but they rarely quantify how well they do it. In this project, our goal is to
use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants and predict the manner in
which the participants did the exercise. More information is available from the website:
http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).

The "classe" variable (of possible values A, B, C, D, E) in the training set represents how well the participants
did the exercise.

### Read and filter the data

Inspection of the data reveals missing data (NA or blank values) and columns of values not suitable for modeling
(names, timestamps, string). We deal with this by filtering the data:

(1) Read the csv file for training
```{r,eval=FALSE}
pml_training <- read.csv("pml-training.csv")
pml_testing <- read.csv("pml-testing.csv")
```

(2) Remove all columns that contain blanks or NA's
```{r,eval=FALSE}
pml_training[pml_training == ""] <- NA
pml_testing[pml_testing == ""] <- NA
pml_training_filter <- Filter(function(x)!any(is.na(x)), pml_training)
pml_testing_filter <- Filter(function(x)!any(is.na(x)), pml_testing)
```

(3) Remove the first 7 columns since they contain names, timestamps & strings
```{r,eval=FALSE}
pml_training_filter <- pml_training_filter [7:length (pml_training_filter)]
pml_testing_filter <- pml_testing_filter [7:length (pml_testing_filter)]
```

Finally, we can split the training data into a training set and a testing set:
```{r,eval=FALSE}
inTrain <- createDataPartition(y = pml_training_filter$classe, p = 0.7, list = FALSE)
training <- pml_training_filter [inTrain, ]
testing <- pml_training_filter [-inTrain, ]
```

### Build the model

We chose a random forest model because this category of model is known to be very accurate. First we implemented random
forest following the class video (function train with method set to rf). It turned out that run time was not practical.
Fortunately, there exists another R implementation of random forest. With that one run time is significantly shorter
(minutes versus hours).

So we fit our trainin data to a random forest model and predict the "classe" variable using everything else as a predictor.

```{r,eval=FALSE}
modFit <- randomForest(classe~., data = training)
```

### Model accuracy

To compute the model accuracy, we use the test dataset that we constructed.

```{r,eval=FALSE}
rfPred <- predict(modFit, testing)
confusionMatrix (testing, rfPred)
```

The output of the confusionMatrix consists of a cross-tabulation of observed and predicted classes with associated
statistics:
```{r,eval=FALSE}
Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1674    0    0    0    0
         B    1 1138    0    0    0
         C    0    3 1023    0    0
         D    0    0    3  961    0
         E    0    0    0    3 1079

Overall Statistics
                                          
               Accuracy : 0.9983          
                 95% CI : (0.9969, 0.9992)
    No Information Rate : 0.2846          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.9979          
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9994   0.9974   0.9971   0.9969   1.0000
Specificity            1.0000   0.9998   0.9994   0.9994   0.9994
Pos Pred Value         1.0000   0.9991   0.9971   0.9969   0.9972
Neg Pred Value         0.9998   0.9994   0.9994   0.9994   1.0000
Prevalence             0.2846   0.1939   0.1743   0.1638   0.1833
Detection Rate         0.2845   0.1934   0.1738   0.1633   0.1833
Detection Prevalence   0.2845   0.1935   0.1743   0.1638   0.1839
Balanced Accuracy      0.9997   0.9986   0.9982   0.9981   0.9997
```

Our model accuracy of 99.83% is quiet good compared to other models (Naive Bayes resulted in an accuracy of 73%,
Linear Discriminant Analysis resulted in an accuracy of 70%, PLS resulted in an accuracy of 38%).  

### Predict the 20 test cases

Using the testing data set, we predict the "classe" variable
```{r,eval=FALSE}
answers <- predict (modFit, pml_testing_filter)
```

We then apply our answer array to the function provided by the instructor:
```{r,eval=FALSE}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
pml_write_files(answers)
```

We provide the results here (all successfully submited).
```{r,eval=FALSE}
 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 
 B  A  B  A  A  E  D  B  A  A  B  C  B  A  E  E  A  B  B  B 
Levels: A B C D E
```